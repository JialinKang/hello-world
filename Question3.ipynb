{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Question3.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNpUUW/XhW/GngFC0C/Zjgx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JialinKang/hello-world/blob/master/Question3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7OMEYxzZCch6",
        "colab_type": "text"
      },
      "source": [
        "**Fit a multilayer neural network to the oasis data to predict Gold_Lesions. Use 10-fold cross-validation to compare the performance where you hold out 10% of the observation and fit on the remainder, then repeat this process 10 times. Compare the cross validated accuracy to the cross validated accuracy for logistic regression. Note, you won't be able to fit a very complex NN model on this data because the size is small.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIzwFCJdCXMI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "oasis = pd.read_csv('https://raw.githubusercontent.com/bcaffo/ds4bme_intro/master/data/oasis.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RA221HuvHgPQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Dropout, Activation\n",
        "from keras.utils import np_utils\n",
        "from keras import layers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TsOHlVVACj19",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "oasis_train = oasis[['FLAIR', 'PD', 'T1', 'T2', 'FLAIR_10', 'PD_10', 'T1_10', 'T2_10', 'FLAIR_20', 'PD_20', 'T1_20', 'T2_20']]\n",
        "oasis_target = oasis[['GOLD_Lesions']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5r6wRyuCnsR",
        "colab_type": "code",
        "outputId": "d9d45021-73b7-47ca-b169-50c60552a9aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        }
      },
      "source": [
        "oasis_train"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>FLAIR</th>\n",
              "      <th>PD</th>\n",
              "      <th>T1</th>\n",
              "      <th>T2</th>\n",
              "      <th>FLAIR_10</th>\n",
              "      <th>PD_10</th>\n",
              "      <th>T1_10</th>\n",
              "      <th>T2_10</th>\n",
              "      <th>FLAIR_20</th>\n",
              "      <th>PD_20</th>\n",
              "      <th>T1_20</th>\n",
              "      <th>T2_20</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.143692</td>\n",
              "      <td>1.586219</td>\n",
              "      <td>-0.799859</td>\n",
              "      <td>1.634467</td>\n",
              "      <td>0.437568</td>\n",
              "      <td>0.823800</td>\n",
              "      <td>-0.002059</td>\n",
              "      <td>0.573663</td>\n",
              "      <td>0.279832</td>\n",
              "      <td>0.548341</td>\n",
              "      <td>0.219136</td>\n",
              "      <td>0.298662</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.652552</td>\n",
              "      <td>1.766672</td>\n",
              "      <td>-1.250992</td>\n",
              "      <td>0.921230</td>\n",
              "      <td>0.663037</td>\n",
              "      <td>0.880250</td>\n",
              "      <td>-0.422060</td>\n",
              "      <td>0.542597</td>\n",
              "      <td>0.422182</td>\n",
              "      <td>0.549711</td>\n",
              "      <td>0.061573</td>\n",
              "      <td>0.280972</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.036099</td>\n",
              "      <td>0.262042</td>\n",
              "      <td>-0.858565</td>\n",
              "      <td>-0.058211</td>\n",
              "      <td>-0.044280</td>\n",
              "      <td>-0.308569</td>\n",
              "      <td>0.014766</td>\n",
              "      <td>-0.256075</td>\n",
              "      <td>-0.136532</td>\n",
              "      <td>-0.350905</td>\n",
              "      <td>0.020673</td>\n",
              "      <td>-0.259914</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.037692</td>\n",
              "      <td>0.011104</td>\n",
              "      <td>-1.228796</td>\n",
              "      <td>-0.470222</td>\n",
              "      <td>-0.013971</td>\n",
              "      <td>-0.000498</td>\n",
              "      <td>-0.395575</td>\n",
              "      <td>-0.221900</td>\n",
              "      <td>0.000807</td>\n",
              "      <td>-0.003085</td>\n",
              "      <td>-0.193249</td>\n",
              "      <td>-0.139284</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.580589</td>\n",
              "      <td>1.730152</td>\n",
              "      <td>-0.860949</td>\n",
              "      <td>1.245609</td>\n",
              "      <td>0.617957</td>\n",
              "      <td>0.866352</td>\n",
              "      <td>-0.099919</td>\n",
              "      <td>0.384261</td>\n",
              "      <td>0.391133</td>\n",
              "      <td>0.608826</td>\n",
              "      <td>0.071648</td>\n",
              "      <td>0.340601</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>3.873210</td>\n",
              "      <td>0.539509</td>\n",
              "      <td>1.075184</td>\n",
              "      <td>0.741517</td>\n",
              "      <td>0.490891</td>\n",
              "      <td>-0.072004</td>\n",
              "      <td>0.490218</td>\n",
              "      <td>-0.202590</td>\n",
              "      <td>0.209201</td>\n",
              "      <td>-0.077513</td>\n",
              "      <td>0.209763</td>\n",
              "      <td>-0.102731</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>1.497552</td>\n",
              "      <td>-0.323060</td>\n",
              "      <td>0.751151</td>\n",
              "      <td>-0.151303</td>\n",
              "      <td>0.091900</td>\n",
              "      <td>-0.482855</td>\n",
              "      <td>0.296390</td>\n",
              "      <td>-0.255905</td>\n",
              "      <td>-0.023249</td>\n",
              "      <td>-0.339573</td>\n",
              "      <td>0.115855</td>\n",
              "      <td>-0.151665</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>1.634460</td>\n",
              "      <td>-0.240130</td>\n",
              "      <td>1.530142</td>\n",
              "      <td>-0.817861</td>\n",
              "      <td>0.195918</td>\n",
              "      <td>0.268417</td>\n",
              "      <td>0.378934</td>\n",
              "      <td>0.050704</td>\n",
              "      <td>0.018602</td>\n",
              "      <td>0.165713</td>\n",
              "      <td>0.246406</td>\n",
              "      <td>0.073374</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>1.484775</td>\n",
              "      <td>0.567067</td>\n",
              "      <td>-0.353472</td>\n",
              "      <td>0.542373</td>\n",
              "      <td>-0.005206</td>\n",
              "      <td>-0.063825</td>\n",
              "      <td>0.136869</td>\n",
              "      <td>-0.120705</td>\n",
              "      <td>0.015719</td>\n",
              "      <td>0.093438</td>\n",
              "      <td>0.010343</td>\n",
              "      <td>-0.006837</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>1.748226</td>\n",
              "      <td>0.633330</td>\n",
              "      <td>0.583970</td>\n",
              "      <td>0.750313</td>\n",
              "      <td>0.503704</td>\n",
              "      <td>0.030620</td>\n",
              "      <td>0.418390</td>\n",
              "      <td>0.173066</td>\n",
              "      <td>0.081150</td>\n",
              "      <td>-0.096228</td>\n",
              "      <td>0.195650</td>\n",
              "      <td>0.026891</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 12 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       FLAIR        PD        T1  ...     PD_20     T1_20     T2_20\n",
              "0   1.143692  1.586219 -0.799859  ...  0.548341  0.219136  0.298662\n",
              "1   1.652552  1.766672 -1.250992  ...  0.549711  0.061573  0.280972\n",
              "2   1.036099  0.262042 -0.858565  ... -0.350905  0.020673 -0.259914\n",
              "3   1.037692  0.011104 -1.228796  ... -0.003085 -0.193249 -0.139284\n",
              "4   1.580589  1.730152 -0.860949  ...  0.608826  0.071648  0.340601\n",
              "..       ...       ...       ...  ...       ...       ...       ...\n",
              "95  3.873210  0.539509  1.075184  ... -0.077513  0.209763 -0.102731\n",
              "96  1.497552 -0.323060  0.751151  ... -0.339573  0.115855 -0.151665\n",
              "97  1.634460 -0.240130  1.530142  ...  0.165713  0.246406  0.073374\n",
              "98  1.484775  0.567067 -0.353472  ...  0.093438  0.010343 -0.006837\n",
              "99  1.748226  0.633330  0.583970  ... -0.096228  0.195650  0.026891\n",
              "\n",
              "[100 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLxZXvETCptA",
        "colab_type": "code",
        "outputId": "254f733a-5c88-43b4-862e-f57264539bfe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        }
      },
      "source": [
        "oasis_target"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>GOLD_Lesions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    GOLD_Lesions\n",
              "0              0\n",
              "1              0\n",
              "2              0\n",
              "3              0\n",
              "4              0\n",
              "..           ...\n",
              "95             1\n",
              "96             1\n",
              "97             1\n",
              "98             1\n",
              "99             1\n",
              "\n",
              "[100 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2PVjnNBXCrte",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mean = oasis_train.mean(axis=0)\n",
        "oasis_train -= mean\n",
        "std = oasis_train.std(axis=0)\n",
        "oasis_train /= std"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUotnUKiCuYS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "\n",
        "\n",
        "\n",
        "def oasis_model():\n",
        "  # model = models.Sequential()\n",
        "  # model.add(layers.Dense(64, activation='relu',input_shape=(oasis_train.shape[1],)))\n",
        "  # model.add(layers.Dense(1))\n",
        "  # model.compile(optimizer='rmsprop',loss='mse',metrics=['mae'])\n",
        "  model = Sequential() \n",
        "  model.add(Dense(96,activation='relu',input_shape=(12,)))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Dense(48,activation='relu'))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Dense(1,activation='sigmoid'))\n",
        "  model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8y3jEnTCzQw",
        "colab_type": "code",
        "outputId": "83864e2e-8df1-415c-f4a1-8a2cb5635147",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "k = 10\n",
        "num_val_samples = len(oasis_train)//k\n",
        "num_epochs = 100\n",
        "all_scores = []\n",
        "sc = []\n",
        "\n",
        "for i in range(k):\n",
        "  print('processing fold #', i)\n",
        "  val_data = oasis_train[i*num_val_samples:(i+1)*num_val_samples]\n",
        "  val_targets = oasis_target[i*num_val_samples:(i+1)*num_val_samples]\n",
        "\n",
        "  partial_train_data = np.concatenate(\n",
        "      [oasis_train[:i*num_val_samples],\n",
        "       oasis_train[(i+1)*num_val_samples:]], axis = 0\n",
        "  )\n",
        "  partial_train_targets = np.concatenate(\n",
        "      [oasis_target[:i*num_val_samples],\n",
        "       oasis_target[(i+1)*num_val_samples:]], axis = 0\n",
        "  )\n",
        "\n",
        "  oasis_model_ep = oasis_model()\n",
        "  oasis_model_ep.fit(partial_train_data, partial_train_targets,\n",
        "          epochs=num_epochs, batch_size=1,verbose=0)\n",
        "  val_mse, val_mae = oasis_model_ep.evaluate(val_data, val_targets, verbose=0)\n",
        "  all_scores.append(val_mae)\n",
        "  sc.append(val_mse)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "processing fold # 0\n",
            "processing fold # 1\n",
            "processing fold # 2\n",
            "processing fold # 3\n",
            "processing fold # 4\n",
            "processing fold # 5\n",
            "processing fold # 6\n",
            "processing fold # 7\n",
            "processing fold # 8\n",
            "processing fold # 9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ise4h-ZxDD2G",
        "colab_type": "code",
        "outputId": "489cc5b2-d3b4-48ac-a913-936fa5fb7089",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "all_scores"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.800000011920929,\n",
              " 0.5,\n",
              " 0.8999999761581421,\n",
              " 0.8999999761581421,\n",
              " 0.8999999761581421,\n",
              " 0.8999999761581421,\n",
              " 0.800000011920929]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79ab6gLrIisa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c94bd2a0-b460-4120-a25d-f315ddcf8240"
      },
      "source": [
        "m = 0\n",
        "for i in all_scores:\n",
        "  m = m + i\n",
        "\n",
        "print('NN model accuacy:',m/10)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NN model accuacy: 0.8699999928474427\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfZYAwsUDMX_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWDquP1CDQYO",
        "colab_type": "code",
        "outputId": "b9fd045d-0498-4d0d-e0ef-dc745200e907",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 541
        }
      },
      "source": [
        "logreg = LogisticRegression()\n",
        "k = 10\n",
        "num_val_samples = len(oasis_train)//k\n",
        "num_epochs = 100\n",
        "log_scores = []\n",
        "\n",
        "for i in range(k):\n",
        "  print('processing fold #', i)\n",
        "  val_data = np.array(oasis_train[i*num_val_samples:(i+1)*num_val_samples])\n",
        "  val_targets = np.array(oasis_target[i*num_val_samples:(i+1)*num_val_samples])\n",
        "\n",
        "  partial_train_data = np.concatenate(\n",
        "      [oasis_train[:i*num_val_samples],\n",
        "       oasis_train[(i+1)*num_val_samples:]], axis = 0\n",
        "  )\n",
        "  partial_train_targets = np.concatenate(\n",
        "      [oasis_target[:i*num_val_samples],\n",
        "       oasis_target[(i+1)*num_val_samples:]], axis = 0\n",
        "  )\n",
        "\n",
        "  logreg = LogisticRegression()\n",
        "  logreg.fit(partial_train_data, partial_train_targets)\n",
        "  pred = logreg.predict(val_data)\n",
        "  acc = 1 - (pred.ravel()!=val_targets.ravel()).sum()/val_targets.size\n",
        "  log_scores.append(acc)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "processing fold # 0\n",
            "processing fold # 1\n",
            "processing fold # 2\n",
            "processing fold # 3\n",
            "processing fold # 4\n",
            "processing fold # 5\n",
            "processing fold # 6\n",
            "processing fold # 7\n",
            "processing fold # 8\n",
            "processing fold # 9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "029CU62jDVCZ",
        "colab_type": "code",
        "outputId": "f003163d-18ed-4ca5-ddc7-ed1e8080a492",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "log_scores"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.0, 1.0, 0.9, 0.8, 0.7, 0.9, 0.9, 0.9, 0.9, 0.8]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSF3o-H7I36T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d8dacd2a-877a-4bbc-d23f-c9d4584fd025"
      },
      "source": [
        "m = 0\n",
        "for i in log_scores:\n",
        "  m = m + i\n",
        "\n",
        "print('LogisticRegression model accuacy:',m/10)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LogisticRegression model accuacy: 0.8800000000000002\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VaNGE-jGDYf_",
        "colab_type": "text"
      },
      "source": [
        "From the above result:\n",
        "\n",
        "We can know that logistic regression is better than the NN model"
      ]
    }
  ]
}