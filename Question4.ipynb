{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Question4.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPcOa636uI2WIaCEh+vw6PB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JialinKang/hello-world/blob/master/Question4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TXqDknG3DzwS",
        "colab_type": "text"
      },
      "source": [
        "**Fit a multilayer neural network model on the SHHS data to predict whether rdi4p > 7 using the variables from the previous HW assigment. Compare the test set accuracy with the penalized model from your previous HW.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WAl4ZK9tDxCc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import keras\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "ssh_data = pd.read_table('https://raw.githubusercontent.com/JialinKang/hello-world/master/shhs1.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lnh45k4jEtlX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Dropout, Activation\n",
        "from keras.utils import np_utils\n",
        "from keras import layers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_GM6UTWEJ4Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "a00fbff6-198e-491e-c254-1e4031dbb50d"
      },
      "source": [
        "j = 0\n",
        "ssh_data['predict'] = np.zeros((len(ssh_data,)))\n",
        "for i in ssh_data['rdi4p']:\n",
        "  if i <=7 :\n",
        "    ssh_data['predict'][j] = 0\n",
        "  else:\n",
        "    ssh_data['predict'][j] = 1\n",
        "  j = j+1"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  import sys\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lux-8RZ0EQ4_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ssh_data.dropna(axis=0)\n",
        "for i in list(ssh_data):\n",
        "    ssh_data = ssh_data[~np.isnan(ssh_data[i])]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ge1kE4eVETjg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label = ssh_data['predict']\n",
        "ssh_data=ssh_data.drop(['pptid','rdi4p','predict'],axis=1)\n",
        "x_train, x_test, y_train, y_test = train_test_split(ssh_data, label, test_size=0.2, random_state=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qE2Olf-OEWxg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3bd67a2b-bd8e-4118-9495-fb5f31cfbbd6"
      },
      "source": [
        "model = Sequential() # creat model\n",
        "model.add(Dense(64,activation='relu',input_shape=(28,)))\n",
        "\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(64,activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1,activation='sigmoid'))\n",
        "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train,y_train,batch_size=300,epochs=50,validation_data=(x_test,y_test)) #train the model and test data for validation\n",
        "score = model.evaluate(x_test,y_test)\n",
        "print(\"loss:\",score[0])\n",
        "print(\"accu:\",score[1])#print accuracy"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 2317 samples, validate on 580 samples\n",
            "Epoch 1/50\n",
            "2317/2317 [==============================] - 0s 154us/step - loss: 20.1874 - accuracy: 0.4644 - val_loss: 11.6203 - val_accuracy: 0.6552\n",
            "Epoch 2/50\n",
            "2317/2317 [==============================] - 0s 13us/step - loss: 14.2358 - accuracy: 0.5896 - val_loss: 5.9610 - val_accuracy: 0.6362\n",
            "Epoch 3/50\n",
            "2317/2317 [==============================] - 0s 11us/step - loss: 10.0882 - accuracy: 0.5416 - val_loss: 2.9980 - val_accuracy: 0.5052\n",
            "Epoch 4/50\n",
            "2317/2317 [==============================] - 0s 11us/step - loss: 9.4923 - accuracy: 0.5166 - val_loss: 3.7024 - val_accuracy: 0.6690\n",
            "Epoch 5/50\n",
            "2317/2317 [==============================] - 0s 11us/step - loss: 7.7183 - accuracy: 0.5697 - val_loss: 2.3273 - val_accuracy: 0.6379\n",
            "Epoch 6/50\n",
            "2317/2317 [==============================] - 0s 11us/step - loss: 6.9782 - accuracy: 0.5343 - val_loss: 1.7232 - val_accuracy: 0.5828\n",
            "Epoch 7/50\n",
            "2317/2317 [==============================] - 0s 12us/step - loss: 5.4855 - accuracy: 0.5611 - val_loss: 1.6827 - val_accuracy: 0.5931\n",
            "Epoch 8/50\n",
            "2317/2317 [==============================] - 0s 11us/step - loss: 5.0046 - accuracy: 0.5675 - val_loss: 1.4275 - val_accuracy: 0.5655\n",
            "Epoch 9/50\n",
            "2317/2317 [==============================] - 0s 13us/step - loss: 4.5005 - accuracy: 0.5516 - val_loss: 1.3299 - val_accuracy: 0.5431\n",
            "Epoch 10/50\n",
            "2317/2317 [==============================] - 0s 12us/step - loss: 3.8482 - accuracy: 0.5641 - val_loss: 1.1889 - val_accuracy: 0.5379\n",
            "Epoch 11/50\n",
            "2317/2317 [==============================] - 0s 12us/step - loss: 3.7199 - accuracy: 0.5477 - val_loss: 1.0796 - val_accuracy: 0.5638\n",
            "Epoch 12/50\n",
            "2317/2317 [==============================] - 0s 12us/step - loss: 3.3449 - accuracy: 0.5589 - val_loss: 0.9731 - val_accuracy: 0.5966\n",
            "Epoch 13/50\n",
            "2317/2317 [==============================] - 0s 12us/step - loss: 2.9537 - accuracy: 0.5714 - val_loss: 0.9682 - val_accuracy: 0.5569\n",
            "Epoch 14/50\n",
            "2317/2317 [==============================] - 0s 11us/step - loss: 2.6796 - accuracy: 0.5520 - val_loss: 0.8760 - val_accuracy: 0.5983\n",
            "Epoch 15/50\n",
            "2317/2317 [==============================] - 0s 11us/step - loss: 2.2783 - accuracy: 0.5788 - val_loss: 0.8121 - val_accuracy: 0.6052\n",
            "Epoch 16/50\n",
            "2317/2317 [==============================] - 0s 15us/step - loss: 2.1139 - accuracy: 0.5688 - val_loss: 0.8094 - val_accuracy: 0.5793\n",
            "Epoch 17/50\n",
            "2317/2317 [==============================] - 0s 11us/step - loss: 2.0332 - accuracy: 0.5662 - val_loss: 0.7791 - val_accuracy: 0.6414\n",
            "Epoch 18/50\n",
            "2317/2317 [==============================] - 0s 11us/step - loss: 1.8887 - accuracy: 0.5710 - val_loss: 0.7416 - val_accuracy: 0.6190\n",
            "Epoch 19/50\n",
            "2317/2317 [==============================] - 0s 11us/step - loss: 1.7260 - accuracy: 0.5602 - val_loss: 0.7223 - val_accuracy: 0.6397\n",
            "Epoch 20/50\n",
            "2317/2317 [==============================] - 0s 12us/step - loss: 1.5615 - accuracy: 0.5593 - val_loss: 0.7190 - val_accuracy: 0.6534\n",
            "Epoch 21/50\n",
            "2317/2317 [==============================] - 0s 14us/step - loss: 1.5413 - accuracy: 0.5477 - val_loss: 0.7103 - val_accuracy: 0.6655\n",
            "Epoch 22/50\n",
            "2317/2317 [==============================] - 0s 11us/step - loss: 1.3768 - accuracy: 0.5831 - val_loss: 0.7046 - val_accuracy: 0.6655\n",
            "Epoch 23/50\n",
            "2317/2317 [==============================] - 0s 12us/step - loss: 1.2129 - accuracy: 0.5719 - val_loss: 0.6819 - val_accuracy: 0.6586\n",
            "Epoch 24/50\n",
            "2317/2317 [==============================] - 0s 14us/step - loss: 1.1962 - accuracy: 0.5770 - val_loss: 0.6640 - val_accuracy: 0.6621\n",
            "Epoch 25/50\n",
            "2317/2317 [==============================] - 0s 13us/step - loss: 1.0632 - accuracy: 0.5654 - val_loss: 0.6538 - val_accuracy: 0.6690\n",
            "Epoch 26/50\n",
            "2317/2317 [==============================] - 0s 13us/step - loss: 1.0354 - accuracy: 0.5900 - val_loss: 0.6512 - val_accuracy: 0.6724\n",
            "Epoch 27/50\n",
            "2317/2317 [==============================] - 0s 11us/step - loss: 0.9515 - accuracy: 0.5779 - val_loss: 0.6392 - val_accuracy: 0.6672\n",
            "Epoch 28/50\n",
            "2317/2317 [==============================] - 0s 10us/step - loss: 0.9105 - accuracy: 0.6016 - val_loss: 0.6403 - val_accuracy: 0.6517\n",
            "Epoch 29/50\n",
            "2317/2317 [==============================] - 0s 12us/step - loss: 0.9234 - accuracy: 0.5770 - val_loss: 0.6294 - val_accuracy: 0.6638\n",
            "Epoch 30/50\n",
            "2317/2317 [==============================] - 0s 14us/step - loss: 0.8662 - accuracy: 0.5900 - val_loss: 0.6254 - val_accuracy: 0.6638\n",
            "Epoch 31/50\n",
            "2317/2317 [==============================] - 0s 14us/step - loss: 0.7935 - accuracy: 0.6120 - val_loss: 0.6252 - val_accuracy: 0.6638\n",
            "Epoch 32/50\n",
            "2317/2317 [==============================] - 0s 12us/step - loss: 0.8373 - accuracy: 0.5913 - val_loss: 0.6272 - val_accuracy: 0.6724\n",
            "Epoch 33/50\n",
            "2317/2317 [==============================] - 0s 11us/step - loss: 0.7707 - accuracy: 0.6267 - val_loss: 0.6286 - val_accuracy: 0.6690\n",
            "Epoch 34/50\n",
            "2317/2317 [==============================] - 0s 11us/step - loss: 0.7937 - accuracy: 0.6111 - val_loss: 0.6288 - val_accuracy: 0.6672\n",
            "Epoch 35/50\n",
            "2317/2317 [==============================] - 0s 12us/step - loss: 0.7463 - accuracy: 0.6198 - val_loss: 0.6296 - val_accuracy: 0.6690\n",
            "Epoch 36/50\n",
            "2317/2317 [==============================] - 0s 12us/step - loss: 0.7228 - accuracy: 0.6254 - val_loss: 0.6293 - val_accuracy: 0.6621\n",
            "Epoch 37/50\n",
            "2317/2317 [==============================] - 0s 12us/step - loss: 0.7232 - accuracy: 0.6237 - val_loss: 0.6275 - val_accuracy: 0.6638\n",
            "Epoch 38/50\n",
            "2317/2317 [==============================] - 0s 12us/step - loss: 0.7443 - accuracy: 0.6185 - val_loss: 0.6301 - val_accuracy: 0.6621\n",
            "Epoch 39/50\n",
            "2317/2317 [==============================] - 0s 11us/step - loss: 0.7107 - accuracy: 0.6172 - val_loss: 0.6268 - val_accuracy: 0.6638\n",
            "Epoch 40/50\n",
            "2317/2317 [==============================] - 0s 12us/step - loss: 0.7099 - accuracy: 0.6219 - val_loss: 0.6286 - val_accuracy: 0.6621\n",
            "Epoch 41/50\n",
            "2317/2317 [==============================] - 0s 12us/step - loss: 0.6918 - accuracy: 0.6206 - val_loss: 0.6272 - val_accuracy: 0.6569\n",
            "Epoch 42/50\n",
            "2317/2317 [==============================] - 0s 12us/step - loss: 0.7019 - accuracy: 0.6189 - val_loss: 0.6283 - val_accuracy: 0.6569\n",
            "Epoch 43/50\n",
            "2317/2317 [==============================] - 0s 12us/step - loss: 0.7035 - accuracy: 0.6237 - val_loss: 0.6333 - val_accuracy: 0.6569\n",
            "Epoch 44/50\n",
            "2317/2317 [==============================] - 0s 11us/step - loss: 0.6795 - accuracy: 0.6319 - val_loss: 0.6324 - val_accuracy: 0.6569\n",
            "Epoch 45/50\n",
            "2317/2317 [==============================] - 0s 11us/step - loss: 0.6797 - accuracy: 0.6245 - val_loss: 0.6291 - val_accuracy: 0.6569\n",
            "Epoch 46/50\n",
            "2317/2317 [==============================] - 0s 12us/step - loss: 0.6798 - accuracy: 0.6392 - val_loss: 0.6281 - val_accuracy: 0.6603\n",
            "Epoch 47/50\n",
            "2317/2317 [==============================] - 0s 13us/step - loss: 0.6752 - accuracy: 0.6362 - val_loss: 0.6265 - val_accuracy: 0.6603\n",
            "Epoch 48/50\n",
            "2317/2317 [==============================] - 0s 13us/step - loss: 0.6710 - accuracy: 0.6258 - val_loss: 0.6259 - val_accuracy: 0.6603\n",
            "Epoch 49/50\n",
            "2317/2317 [==============================] - 0s 13us/step - loss: 0.6923 - accuracy: 0.6262 - val_loss: 0.6256 - val_accuracy: 0.6603\n",
            "Epoch 50/50\n",
            "2317/2317 [==============================] - 0s 12us/step - loss: 0.6710 - accuracy: 0.6362 - val_loss: 0.6264 - val_accuracy: 0.6603\n",
            "580/580 [==============================] - 0s 27us/step\n",
            "loss: 0.6264310734025363\n",
            "accu: 0.6603448390960693\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MdIFh_6zE5wG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "59fb9548-c859-4939-dd61-8ce9ec969cf6"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "import numpy as np\n",
        "\n",
        "# Logsitic regression with penalty\n",
        "logisticRegr = LogisticRegression(penalty='l1', solver='saga')\n",
        "logisticRegr.fit(x_train, y_train)\n",
        "l1score = logisticRegr.score(x_test, y_test)\n",
        "print('Accuracy for logistic regression model with lasso penalty: ' + str(l1score))\n",
        "logisticRegr = LogisticRegression(penalty='l2', solver='saga')\n",
        "logisticRegr.fit(x_train, y_train)\n",
        "l2score = logisticRegr.score(x_test, y_test)\n",
        "print('Accuracy for logistic regression model with ridge penalty: ' + str(l2score))\n",
        "logisticRegr = LogisticRegression(penalty='elasticnet', solver='saga', l1_ratio=0.2)\n",
        "logisticRegr.fit(x_train, y_train)\n",
        "enscore = logisticRegr.score(x_test, y_test)\n",
        "print('Accuracy for logistic regression model with elasticnet penalty: ' + str(enscore))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy for logistic regression model with lasso penalty: 0.6810344827586207\n",
            "Accuracy for logistic regression model with ridge penalty: 0.6810344827586207\n",
            "Accuracy for logistic regression model with elasticnet penalty: 0.6810344827586207\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mA381d1hFHL_",
        "colab_type": "text"
      },
      "source": [
        "From above result, we can know:\n",
        "\n",
        "NN model accuacy: 0.6603\n",
        "\n",
        "Accuracy for logistic regression model with lasso penalty: 0.6810344827586207\n",
        "\n",
        "Accuracy for logistic regression model with ridge penalty: 0.6810344827586207\n",
        "\n",
        "Accuracy for logistic regression model with elasticnet penalty: 0.6810344827586207\n",
        "\n",
        "So in this case the logistic regression model is better than NN model"
      ]
    }
  ]
}